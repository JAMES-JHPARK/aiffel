{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8190164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "sns.set(font='NanumGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571dc1b",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3707813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
      ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
      ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n",
      "\n",
      ">> Much of personal computing is about \"can you top this?\"\n",
      ">> Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.\n",
      ">> “Guard robots are used privately and professionally to detect intruders or fire,” Karlsson said.\n",
      ">> Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",
      ">> Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.\n"
     ]
    }
   ],
   "source": [
    "with open('korean-english-park.train.ko', 'r') as f:\n",
    "    raw_ko = f.read().splitlines()\n",
    "    \n",
    "with open('korean-english-park.train.en', 'r') as f:\n",
    "    raw_en = f.read().splitlines()\n",
    "    \n",
    "for sen in raw_ko[0:100][::20]: print(\">>\", sen)\n",
    "print()\n",
    "for sen in raw_en[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa80c7",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 정제\n",
    "\n",
    "1. set 데이터형이 중복을 허용하지 않는다는 것을 활용해 중복된 데이터를 제거하도록 합니다. 데이터의 병렬 쌍이 흐트러지지 않게 주의하세요! 중복을 제거한 데이터를 cleaned_corpus 에 저장합니다.  \n",
    "\n",
    "2. 앞서 정의한 preprocessing() 함수는 한글에서는 동작하지 않습니다. 한글에 적용할 수 있는 정규식을 추가하여 함수를 재정의하세요!  \n",
    "  \n",
    "3. 타겟 언어인 영문엔 <start> 토큰과 <end> 토큰을 추가하고 split() 함수를 이용하여 토큰화합니다. 한글 토큰화는 KoNLPy의 mecab 클래스를 사용합니다.  \n",
    "  \n",
    "모든 데이터를 사용할 경우 학습에 굉장히 오랜 시간이 걸립니다. cleaned_corpus로부터 토큰의 길이가 40 이하인 데이터를 선별하여 eng_corpus와 kor_corpus를 각각 구축하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd829ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ko' : raw_ko,\n",
    "    'en' : raw_en\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070db3b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dropping duplicates :  (94123, 2)\n",
      "after dropping duplicates :  (74849, 2)\n"
     ]
    }
   ],
   "source": [
    "print('before dropping duplicates : ', df.shape)\n",
    "df.drop_duplicates(['ko'], inplace=True, ignore_index=True)\n",
    "df.drop_duplicates(['en'], inplace=True, ignore_index=True)\n",
    "print('after dropping duplicates : ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0657bbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74849, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치는 없음\n",
    "df.dropna(how='any', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b37c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74849, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6c7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_korean_sentence(sentence, s_token=False, e_token=False):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^가-힣?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5638b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_english_sentence(sentence, s_token=True, e_token=True):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca153f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "for pair in zip(df['ko'], df['en']):\n",
    "    (ko, en) = pair\n",
    "    \n",
    "    enc_corpus.append(preprocess_korean_sentence(ko))\n",
    "    dec_corpus.append(preprocess_english_sentence(en, s_token=True, e_token=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31db461",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?',\n",
       " '모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하지 않는다 .',\n",
       " '그러나 이것은 또한 책상도 필요로 하지 않는다 .',\n",
       " '. 달러하는 이 최첨단 무선 광마우스는 허공에서 팔목 , 팔 , 그외에 어떤 부분이든 그 움직임에따라 커서의 움직임을 조절하는 회전 운동 센서를 사용하고 있다 .',\n",
       " '정보 관리들은 동남 아시아에서의 선박들에 대한 많은 테러 계획들이 실패로 돌아갔음을 밝혔으며 , 세계 해상 교역량의 거의 분의 을 운송하는 좁은 해로인 말라카 해협이 테러 공격을 당하기 쉽다고 경고하고 있다 .',\n",
       " '이 지역에 있는 미국 선박과 상업용 선박들에 대한 알카에다의 테러 시도 중 여러 건이 실패했다는 것을 알게 된 후에 , 전문가들은 테러 조직이 여전히 세계 경제에 타격을 입히려 한다고 경고하고 있으며 , 동남 아시아에 있는 세계 경제의 주요 통로가 위험에 처해 있다고 그들은 생각하고 있다 .',\n",
       " '국립 과학 학회가 발표한 새 보고서에따르면 , 복잡한 임무를 수행해야 하는 군인들이나 보다 오랜 시간 동안 경계를 늦추지 않고 있기 위해 도움이 필요한 군인들에게 카페인이 반응 시간을 증가시키고 임무 수행 능력을 향상시키는데 도움이 된다고 한다 .',\n",
       " '이 보고서에따르면 , 특히 , 군사 작전에서 생사가 걸린 상황이 될 수도 있는 반응 속도와 시각 및 청각의 경계 상태를 유지시키기 위해 카페인이 사용될 수도 있다 . 고 한다 .',\n",
       " '결정적인 순간에 그들의 능력을 증가시켜 줄 그 무엇이 매우 중요합니다 .',\n",
       " '연구가들이 이미 커피 대체품으로서 음식 대용 과자나 껌에 카페인을 첨가하는 방법을 연구하고 있다고 는 말했다 .']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "465aee60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> much of personal computing is about can you top this ? <end>',\n",
       " '<start> so a mention a few weeks ago about a rechargeable wireless optical mouse brought in another rechargeable , wireless mouse . <end>',\n",
       " '<start> like all optical mice , but it also doesn t need a desk . <end>',\n",
       " '<start> uses gyroscopic sensors to control the cursor movement as you move your wrist , arm , whatever through the air . <end>',\n",
       " '<start> intelligence officials have revealed a spate of foiled plots on ships in southeast asia and are warning that a narrow stretch of water carrying almost one third of the world s maritime trade is vulnerable to a terror attack . <end>',\n",
       " '<start> after learning of several foiled al qaeda attempts on u . s . and commercial ships in the area , experts are warning that the terror network still wants to cripple the global economy , the world s economic jugular vein in southeast asia is at risk . <end>',\n",
       " '<start> caffeine can help increase reaction time and improve performance for military servicemen who must perform complex tasks or who need help staying alert for longer periods of time , according to a new report by the national academy of sciences . <end>',\n",
       " '<start> specifically , it can be used in maintaining speed of reactions and visual and auditory vigilance , which in military operations could be a life or death situation , according to the report . <end>',\n",
       " '<start> something that will boost their capabilities at crucial moments is very important . <end>',\n",
       " '<start> researchers are already exploring ways to put caffeine in nutrition bars or chewing gum as alternatives to coffee , archibald said . <end>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971f51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_corpus = [ x for x in enc_corpus if len(x.split())<=40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b772257",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_corpus = [ x for x in dec_corpus if len(x.split())<=40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724f425",
   "metadata": {},
   "source": [
    "## Step 3. 데이터 토큰화\n",
    "\n",
    "앞서 정의한 tokenize() 함수를 사용해 데이터를 텐서로 변환하고 각각의 tokenizer를 얻으세요! 단어의 수는 실험을 통해 적당한 값을 맞춰주도록 합니다! (최소 10,000 이상!)  \n",
    "  \n",
    "❗ 주의: 난이도에 비해 데이터가 많지 않아 훈련 데이터와 검증 데이터를 따로 나누지는 않습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b499e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mecab_tokenize(data):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    m = Mecab()\n",
    "    \n",
    "    mecab_corpus = []\n",
    "    \n",
    "    max_len = 40\n",
    "    \n",
    "    for sentence in data:\n",
    "        mecab_corpus.append(m.morphs(sentence))\n",
    "\n",
    "    tokenizer.fit_on_texts(mecab_corpus)\n",
    "    mecab_tensor = tokenizer.texts_to_sequences(mecab_corpus)\n",
    "    mecab_tensor = tf.keras.preprocessing.sequence.pad_sequences(mecab_tensor, padding='post', maxlen=max_len)\n",
    "    return mecab_tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68525fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tensor, enc_tokenizer = get_mecab_tokenize(enc_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "991a3a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    \n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8060e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tensor, dec_tokenizer = tokenize(dec_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89cdc2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    4,   265,     7,  1229,  7110,    16,    42,    92,    86,\n",
       "          204,    40,   221,     5,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0],\n",
       "       [    4,   133,     8,  4122,     8,   373,   361,   268,    42,\n",
       "            8, 14496,  3346, 16657,  5466,   955,     9,   177, 14496,\n",
       "            3,  3346,  5466,     2,     5,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0],\n",
       "       [    4,   156,    76, 16657,  4123,     3,    32,    19,    51,\n",
       "          976,    77,   448,     8,  6819,     2,     5,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0],\n",
       "       [    4,  2932, 26114,  7821,     6,   430,     1, 26115,  1215,\n",
       "           22,    86,   399,   308,  7444,     3,  2637,     3,  3011,\n",
       "          152,     1,   310,     2,     5,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0],\n",
       "       [    4,  4037,     3,    19,    92,    29,   254,     9,  4888,\n",
       "         1533,     7,  8243,    10,  6820,    10, 26116, 10677,     3,\n",
       "           54,     9,   101,  1067,    87,    29,     8,   264,    62,\n",
       "          249,   746,     3,    91,     6,     1,   189,     2,     5,\n",
       "            0,     0,     0,     0],\n",
       "       [    4,   747,    15,    33,  1829,    43,  7445,    21,  2143,\n",
       "         3806,    16,   237,   652,     2,     5,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0],\n",
       "       [    4,   969,    30,   330,  7446,  1548,     6,   380,  7111,\n",
       "            9,  8693,  3463,    62, 14497,  9278,    22,  8244,     6,\n",
       "         2973,     3, 26117,    12,     2,     5,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0],\n",
       "       [    4,     8,   840,  8694,     7,  7111,     3,    42, 12846,\n",
       "            3,    51,  1626,  2741,     9,  9279,  2279,  8245,    10,\n",
       "          135,    29,  1197,  4654,     9,  2406,    82,     7,     1,\n",
       "         2279,  8245,   500,    21,   182,  8246,     3,     1,   562,\n",
       "          164,     2,     5,     0],\n",
       "       [    4,     1,  1198,     7,  2603,    16,   188,     7,     1,\n",
       "          116,  1959,     7,  4765,     3,     8,   729,   735,  8247,\n",
       "           25,   663,     6, 10678,     1,    59,    14,  3012,  3880,\n",
       "            2,     5,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0],\n",
       "       [    4,  2567,     6,  7822,   872,     9,   670,     3,  5824,\n",
       "            1,   475,  6040,     6,     2,  1991,  3285,     2,   214,\n",
       "            3,     1,   194,     7,  1627,    12,     2,     5,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5a1a801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66407"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dec_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d70211e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74641"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee2666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tensor = enc_tensor[:10000]\n",
    "dec_tensor = dec_tensor[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d01b10",
   "metadata": {},
   "source": [
    "## Step 4. 모델 설계\n",
    "\n",
    "한국어를 영어로 잘 번역해 줄 멋진 Attention 기반 Seq2seq 모델을 설계하세요!  \n",
    "앞서 만든 모델에 Dropout 모듈을 추가하면 성능이 더 좋아집니다!     \n",
    "Embedding Size와 Hidden Size는 실험을 통해 적당한 값을 맞춰 주도록 합니다!    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9b5d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbf42207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35495852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e92f73e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output: (32, 30, 1024)\n",
      "Decoder Output: (32, 40948)\n",
      "Decoder Hidden State: (32, 1024)\n",
      "Attention: (32, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE     = 32\n",
    "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
    "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
    "\n",
    "units         = 1024\n",
    "embedding_dim = 512\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
    "\n",
    "# sample input\n",
    "sequence_len = 30\n",
    "\n",
    "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
    "sample_output = encoder(sample_enc)\n",
    "\n",
    "print ('Encoder Output:', sample_output.shape)\n",
    "\n",
    "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
    "\n",
    "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                     sample_state, sample_output)\n",
    "\n",
    "print ('Decoder Output:', sample_logits.shape)\n",
    "print ('Decoder Hidden State:', h_dec.shape)\n",
    "print ('Attention:', attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ce1f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eaf1db",
   "metadata": {},
   "source": [
    "## Step 5. 훈련하기\n",
    "\n",
    "훈련엔 위에서 사용한 코드를 그대로 사용하되, eval_step() 부분이 없음에 유의합니다! 매 스텝 아래의 예문에 대한 번역을 생성하여 본인이 생각하기에 가장 멋지게 번역한 Case를 제출하세요! (Attention Map을 시각화해보는 것도 재밌을 거예요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3155a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "            \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a14743aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e17013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 313/313 [03:20<00:00,  1.56it/s, Loss 4.3262]\n",
      "Epoch  2:  29%|██▉       | 91/313 [00:38<01:36,  2.30it/s, Loss 4.0434]"
     ]
    }
   ],
   "source": [
    "# Training Process\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_tensor.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_tensor[idx:idx+BATCH_SIZE],\n",
    "                                dec_tensor[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e9dca",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2fab3f",
   "metadata": {},
   "source": [
    "**배운점**\n",
    "  \n",
    "* 성능이 떨어지지만 단순 번역기를 만들어보았다.\n",
    "  \n",
    "**아쉬운점**\n",
    "  \n",
    "* 어제 결석으로 짧은시간 동안 실습하느라 최종 번역결과를 확인하지 못했다.\n",
    "  \n",
    "**느낀점**\n",
    "\n",
    "* 데이터 변환이나 전처리, 토크나이징 등 기본적인 기술에 대해 계속해서 까먹는다. 반복 숙달이 필요하다.\n",
    "\n",
    "**어려웠던 점**\n",
    "\n",
    "* Training 하는 시간이 길고 GPU 용량 문제가 있었다.\n",
    "* 토크나이징을 여러번 해봤는데 새삼스럽게 데이터 처리가 헷갈렸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d696df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
